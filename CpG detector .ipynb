{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6f2194",
   "metadata": {},
   "source": [
    "# CpG Detector using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bea78",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "##### This project focuses on predicting the occurrence of CpG sites in DNA sequences using an LSTM-based deep learning model. The dataset consists of randomly generated DNA sequences, which are converted into numerical representations for training. The model learns patterns in the sequences and predicts the CpG site count.\n",
    "\n",
    "##### To handle sequences of varying lengths, we implemented padding and packing techniques using PyTorch's pack_padded_sequence. The project includes data preparation, model training, evaluation, and a prediction function to test unseen sequences. This approach demonstrates the application of LSTMs in bioinformatics for sequence-based prediction tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a30f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading torch-2.4.1-cp38-cp38-win_amd64.whl (199.4 MB)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "\n",
      "Requirement already satisfied: sympy in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from torch) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nitheesh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: typing-extensions, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed torch-2.4.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34f7af",
   "metadata": {},
   "source": [
    "##  2. Importing Required Libraries\n",
    "##### Loading necessary packages for data handling, model building, and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca7d7d",
   "metadata": {},
   "source": [
    "## 3. Setting Seed for Reproducibility\n",
    "##### Ensuring consistent results across different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ab661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "\n",
    "\n",
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# Use this for getting x label \n",
    "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = { a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = { i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be1f5a",
   "metadata": {},
   "source": [
    "## 4. Data Preparation and Generation\n",
    "\n",
    "##### *  Generating synthetic DNA sequences\n",
    "##### * Converting DNA sequences to integer format\n",
    "##### * Counting CpG sites as target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913cbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data \n",
    "def prepare_data(num_samples=100):\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples)) # generate the dna sequences\n",
    "    temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train] # converting dna to int\n",
    "    y_dna_seqs = [count_cpgs(seq) for seq in temp] # target\n",
    "    return X_dna_seqs_train, y_dna_seqs \n",
    "\n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075c3b7",
   "metadata": {},
   "source": [
    "## Verifying Generated Data\n",
    "#### This section prints the samples from the generated training data (train_x ,train_y  , test_x ,train_y) to verify the data generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f433e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 1, 1, 1, 1, 1, 1, 0, 4, 1, 2, 0, 3, 1, 4, 0, 2, 1, 0, 2, 3, 3, 1, 2, 2, 1, 3, 4, 4, 3, 2, 3, 2, 0, 2, 4, 2, 3, 4, 4, 1, 3, 3, 4, 1, 2, 1, 1, 4, 2, 2, 2, 3, 2, 4, 2, 3, 1, 4, 3, 4, 1, 4, 1, 1, 2, 1, 0, 3, 3, 3, 0, 3, 0, 1, 1, 3, 3, 2, 1, 3, 2, 2, 1, 2, 4, 1, 4, 1, 3, 1, 4, 0, 4, 4, 0, 2, 4, 4, 2, 1, 2, 1, 1, 4, 0, 1, 1, 0, 3, 4, 4, 4, 0, 3, 2, 0, 4, 0, 1, 2, 0, 3, 2, 2, 4, 4], [0, 3, 4, 2, 0, 0, 2, 2, 1, 3, 4, 4, 4, 3, 1, 1, 2, 0, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 4, 2, 3, 1, 2, 3, 0, 2, 3, 3, 0, 0, 0, 4, 0, 2, 1, 3, 3, 4, 3, 2, 0, 2, 4, 3, 1, 1, 0, 0, 2, 1, 1, 2, 2, 4, 3, 2, 0, 2, 1, 0, 2, 3, 3, 4, 4, 3, 0, 2, 4, 2, 1, 0, 2, 1, 4, 1, 0, 1, 1, 0, 3, 2, 0, 2, 2, 1, 0, 1, 1, 4, 3, 1, 4, 3, 4, 0, 4, 0, 0, 4, 1, 4, 2, 4, 3, 2, 1, 4, 2, 2, 0, 2, 0, 0, 1], [0, 0, 4, 2, 0, 2, 3, 1, 4, 2, 0, 0, 0, 2, 3, 3, 3, 3, 2, 1, 1, 3, 2, 0, 4, 0, 4, 2, 2, 2, 1, 1, 2, 3, 1, 3, 3, 2, 1, 3, 4, 4, 3, 1, 3, 3, 1, 0, 4, 0, 3, 4, 1, 1, 0, 0, 4, 1, 2, 0, 3, 4, 4, 0, 1, 3, 0, 4, 0, 1, 2, 4, 1, 0, 4, 3, 2, 1, 3, 0, 4, 0, 1, 2, 4, 4, 0, 4, 3, 2, 1, 4, 0, 4, 3, 1, 4, 0, 0, 2, 1, 3, 2, 1, 2, 1, 2, 4, 0, 2, 1, 1, 1, 4, 0, 0, 4, 1, 4, 4, 0, 3, 2, 3, 4, 4, 3, 4]]\n",
      "------------\n",
      "[5, 6, 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[:3])\n",
    "print(\"------------\")\n",
    "print(train_y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8091b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 3, 3, 0, 2, 3, 2, 2, 2, 0, 2, 4, 2, 4, 4, 1, 3, 3, 3, 3, 3, 1, 1, 0, 0, 2, 1, 4, 4, 4, 0, 3, 1, 2, 4, 3, 0, 3, 4, 0, 2, 3, 4, 0, 4, 3, 2, 1, 1, 1, 4, 1, 2, 4, 3, 0, 1, 0, 0, 4, 3, 2, 2, 3, 4, 3, 4, 1, 1, 4, 4, 1, 4, 0, 0, 2, 3, 0, 4, 1, 2, 4, 3, 4, 4, 0, 0, 3, 2, 0, 2, 2, 1, 2, 0, 3, 2, 2, 2, 1, 3, 0, 1, 3, 0, 4, 3, 1, 3, 0, 0, 0, 3, 0, 4, 0, 1, 3, 2, 2, 1, 1, 2, 2, 1, 0, 3, 3], [3, 3, 2, 4, 3, 2, 3, 2, 0, 2, 1, 4, 2, 0, 2, 0, 2, 1, 0, 3, 4, 3, 0, 4, 4, 3, 2, 1, 4, 1, 3, 2, 2, 2, 1, 4, 4, 0, 4, 1, 3, 2, 2, 0, 3, 3, 0, 2, 3, 0, 0, 0, 2, 4, 4, 2, 0, 2, 4, 1, 2, 1, 0, 2, 2, 0, 2, 1, 3, 3, 1, 3, 2, 2, 2, 0, 2, 3, 4, 4, 2, 1, 1, 1, 3, 1, 0, 2, 1, 3, 0, 0, 0, 3, 1, 4, 4, 1, 1, 4, 3, 3, 0, 4, 1, 3, 4, 3, 0, 4, 0, 2, 3, 0, 3, 2, 2, 1, 0, 2, 0, 4, 3, 3, 1, 1, 1, 3], [0, 3, 0, 4, 4, 3, 4, 0, 4, 4, 0, 4, 0, 2, 2, 2, 3, 0, 3, 2, 1, 1, 4, 3, 4, 2, 3, 3, 1, 3, 1, 2, 0, 4, 4, 0, 4, 1, 2, 0, 1, 2, 4, 3, 2, 4, 3, 1, 3, 1, 2, 3, 0, 2, 2, 3, 2, 0, 1, 4, 1, 0, 0, 2, 3, 4, 3, 4, 3, 2, 4, 4, 3, 2, 4, 1, 0, 0, 0, 2, 2, 2, 0, 1, 2, 1, 3, 3, 0, 4, 4, 3, 0, 3, 0, 0, 2, 0, 3, 2, 1, 2, 3, 2, 3, 2, 4, 0, 4, 1, 0, 3, 1, 4, 3, 2, 0, 2, 1, 1, 2, 2, 0, 0, 4, 4, 0, 3]]\n",
      "---------\n",
      "[4, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "print(test_x[:3])\n",
    "print(\"---------\")\n",
    "print(test_y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbea07",
   "metadata": {},
   "source": [
    "## 5. LSTM Model Configuration\n",
    "##### Defining hyperparameters (LSTM layers, hidden units, learning rate, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bea2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_HIDDEN = 64\n",
    "LSTM_LAYER = 2\n",
    "LSTM_BIDIRECTIONAL = True   #  Allows the LSTM model to learn from both past and future contexts, improving performance.\n",
    "DROPOUT_RATE = 0.3   #  Helps prevent overfitting by randomly deactivating some neurons during training.\n",
    "EMBEDDING_DIM = 32\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epoch_num = 4\n",
    "WEIGHT_DECAY = 1e-5  #  Used in the optimizer to apply L2 regularization, which helps in controlling overfitting.\n",
    "GRAD_CLIP = 5.0  #  Prevents exploding gradients by capping the gradient values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b26b0",
   "metadata": {},
   "source": [
    "## 6. Creating PyTorch Datasets and DataLoaders\n",
    "\n",
    "##### * Implementing a custom PyTorch dataset\n",
    "##### * Defining data loaders for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f55e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.sequences[index], dtype=torch.long), torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "train_dataset = MyDataset(train_x, train_y)\n",
    "test_dataset = MyDataset(test_x, test_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ca08a",
   "metadata": {},
   "source": [
    "## 7. LSTM Model Definition: CpG Predictor \n",
    "\n",
    "##### * Creating an embedding layer for DNA sequences\n",
    "##### * Implementing LSTM layers for sequence modeling\n",
    "##### * Adding a fully connected output layer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0b6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class CpGPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=5, embedding_dim=EMBEDDING_DIM)\n",
    "        self.lstm = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=LSTM_HIDDEN, \n",
    "                            num_layers=LSTM_LAYER, batch_first=True, \n",
    "                            bidirectional=LSTM_BIDIRECTIONAL, dropout=DROPOUT_RATE)\n",
    "        self.classifier = nn.Linear(LSTM_HIDDEN * (2 if LSTM_BIDIRECTIONAL else 1), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        logits = self.classifier(lstm_out[:, -1, :])\n",
    "        return logits.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a07a7",
   "metadata": {},
   "source": [
    "## 8. Initializing Model, Loss Function, and Optimizer\n",
    "\n",
    "##### * Setting up the loss function (Mean Squared Error)\n",
    "\n",
    "##### * Configuring the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534996ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model and Optimizer\n",
    "model = CpGPredictor()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902e6c6",
   "metadata": {},
   "source": [
    "## 9. Training the LSTM Model\n",
    "##### * Implementing the training loop\n",
    "\n",
    "##### * Performing forward and backward propagation\n",
    "\n",
    "##### *  Updating model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c199a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 612.8225\n",
      "Epoch 2, Loss: 268.9088\n",
      "Epoch 3, Loss: 268.6634\n",
      "Epoch 4, Loss: 264.5030\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    t_loss = 0.0\n",
    "    for batch_x, batch_y in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {t_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a50f9d",
   "metadata": {},
   "source": [
    "## 10. LSTM Evaluation\n",
    "##### * Switching to evaluation mode\n",
    "\n",
    "##### * Making predictions on test data\n",
    "\n",
    "##### * Collecting and storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d3d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "res_gs = []\n",
    "res_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_data_loader:\n",
    "        output = model(batch_x)\n",
    "        res_gs.extend(batch_y.tolist())\n",
    "        res_pred.extend(output.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ed24f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on test data: 1.5569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(res_gs, res_pred)\n",
    "print(f\"Mean Absolute Error (MAE) on test data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0bb5a",
   "metadata": {},
   "source": [
    "##  11. Predicting CpG Counts for New Sequences\n",
    "##### Function to convert DNA sequence input into model predictions\n",
    "\n",
    "##### * Testing with example DNA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5293f7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted CpG count for 'NCACANNTNCGGA': 5.14\n"
     ]
    }
   ],
   "source": [
    "# Prediction Feature: Convert DNA sequence to model input and get prediction\n",
    "def predict_cpg_count(dna_sequence: str):\n",
    "    int_sequence = [dna2int.get(base, 0) for base in dna_sequence]  # Convert DNA bases to integers\n",
    "    input_tensor = torch.tensor([int_sequence], dtype=torch.long)   # Convert to tensor\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    return prediction.item()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_sequence = \"NCACANNTNCGGA\"\n",
    "predicted_cpg_count = predict_cpg_count(test_sequence)\n",
    "print(f\"Predicted CpG count for '{test_sequence}': {predicted_cpg_count:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c63d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0fdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e13f9d",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593deaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47bc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c7620d",
   "metadata": {},
   "source": [
    "# 12. Handling Variable-Length DNA Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f8b52",
   "metadata": {},
   "source": [
    "### Random Seed and Sequence Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8886908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "random.seed(13)\n",
    "\n",
    "# Generating Random DNA Sequences\n",
    "#The rand_sequence_var_len() function generates variable-length DNA sequences with random nucleotide values.\n",
    "#These sequences are converted into their corresponding numerical representations.\n",
    "\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence_var_len(n_seqs: int, lb: int = 16, ub: int = 128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        seq_len = random.randint(lb, ub)\n",
    "        yield [random.randint(1, 5) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers\n",
    "alphabet = 'NACGT'\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}\n",
    "dna2int.update({\"pad\": 0})\n",
    "int2dna.update({0: \"<pad>\"})\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b49f3c",
   "metadata": {},
   "source": [
    "## 13. Generating Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b6c9c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "def prepare_data(num_samples=100, min_len=16, max_len=128):\n",
    "    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))\n",
    "    temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train]\n",
    "    y_dna_seqs = [count_cpgs(seq) for seq in temp]\n",
    "    return X_dna_seqs_train, y_dna_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238a2a",
   "metadata": {},
   "source": [
    "## 14. Controlled Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f3c6ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len, max_len = 64, 128\n",
    "train_x, train_y = prepare_data(2048, min_len, max_len)\n",
    "test_x, test_y = prepare_data(512, min_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5ee75b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, lists, labels) -> None:\n",
    "        self.lists = lists\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.LongTensor(self.lists[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778bfde",
   "metadata": {},
   "source": [
    "## 15. Padding Variable-Length Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9e3452b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for variable-length sequences\n",
    "class PadSequence:\n",
    "    def __call__(self, batch):\n",
    "        sequences, labels = zip(*batch)\n",
    "        lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "        padded_sequences = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in sequences], batch_first=True, padding_value=0)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        return padded_sequences, lengths, labels\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = MyDataset(train_x, train_y)\n",
    "test_dataset = MyDataset(test_x, test_y)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=PadSequence())\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=PadSequence())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f9225",
   "metadata": {},
   "source": [
    "## 16. LSTM Model for Variable-Length Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "15aa1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class CpGPredictorVarLen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CpGPredictorVarLen, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=6, embedding_dim=16)\n",
    "        self.lstm = nn.LSTM(input_size=16, hidden_size=64, num_layers=3,dropout=0.2, batch_first=True)\n",
    "        self.classifier = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x_packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, _ = self.lstm(x_packed)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        logits = self.classifier(lstm_out[:, -1, :])\n",
    "        return logits.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3091bf6",
   "metadata": {},
   "source": [
    "## 17. Model loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f6ad356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CpGPredictorVarLen()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392b277",
   "metadata": {},
   "source": [
    "## 18. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d350513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-34b29c3c4efc>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in sequences], batch_first=True, padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1121.1155\n",
      "Epoch 2, Loss: 1075.7621\n",
      "Epoch 3, Loss: 1056.9942\n",
      "Epoch 4, Loss: 1024.1830\n",
      "Epoch 5, Loss: 1001.6663\n",
      "Epoch 6, Loss: 974.3478\n",
      "Epoch 7, Loss: 939.2596\n",
      "Epoch 8, Loss: 923.8299\n",
      "Epoch 9, Loss: 900.7290\n",
      "Epoch 10, Loss: 870.1682\n",
      "Epoch 11, Loss: 844.4788\n",
      "Epoch 12, Loss: 829.3928\n",
      "Epoch 13, Loss: 804.0160\n",
      "Epoch 14, Loss: 783.2110\n",
      "Epoch 15, Loss: 769.9051\n",
      "Training and evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epoch_num = 15\n",
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    t_loss = 0.0\n",
    "    for batch_x, lengths, batch_y in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x, lengths)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {t_loss:.4f}\")\n",
    "\n",
    "print(\"Training and evaluation completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400c88a",
   "metadata": {},
   "source": [
    "## 19. Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8edaa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-34b29c3c4efc>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in sequences], batch_first=True, padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "MAE: 2.8953, R² Score: -2.0702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, lengths, batch_y in test_loader:\n",
    "            output = model(batch_x, lengths)\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            actuals.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    print(f\"Evaluation Results:\\nMAE: {mae:.4f}, R² Score: {r2:.4f}\")\n",
    "\n",
    "# Call evaluation function\n",
    "evaluate_model(model, test_data_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37d6fa",
   "metadata": {},
   "source": [
    "## 20. Predicting CpG Counts from Variable-Length DNA Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "79104c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted CpG count for sequence 'NCACCGGA': 4.8976\n"
     ]
    }
   ],
   "source": [
    "def predict_cpg(model, input_sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.LongTensor(list(dnaseq_to_intseq(input_sequence))).unsqueeze(0)\n",
    "        length_tensor = torch.tensor([len(input_sequence)])\n",
    "        prediction = model(input_tensor, length_tensor)\n",
    "        return prediction.item()\n",
    "\n",
    "# Example prediction\n",
    "example_sequence = \"NCACCGGA\"  # Replace with your sequence\n",
    "predicted_cpg = predict_cpg(model, example_sequence)\n",
    "print(f\"Predicted CpG count for sequence '{example_sequence}': {predicted_cpg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a764e",
   "metadata": {},
   "source": [
    "## 21. save the trained model\n",
    "##### The final trained model is saved to a specified directory for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5ce1609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Nitheesh\\OneDrive\\Desktop\\brototype\\CpG Detector\\CpG detector model\\cpg_predictor.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = r\"C:\\Users\\Nitheesh\\OneDrive\\Desktop\\brototype\\CpG Detector\\CpG detector model\\cpg_predictor.pth\"  # Replace with your desired path\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce43e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
